{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# os.makedirs('/home/l/liny/ruofan/lightly/datasets/targetlist-merge/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for brand in os.listdir('/home/l/liny/ruofan/lightly/datasets/targetlist/train/'):\n",
    "#     os.makedirs(os.path.join('/home/l/liny/ruofan/lightly/datasets/targetlist-merge/', brand), exist_ok=True)\n",
    "#     for file in os.listdir(os.path.join('/home/l/liny/ruofan/lightly/datasets/targetlist/train/', brand)):\n",
    "#         shutil.copyfile(os.path.join('/home/l/liny/ruofan/lightly/datasets/targetlist/train/', brand, file),\n",
    "#                        os.path.join('/home/l/liny/ruofan/lightly/datasets/targetlist-merge/', brand, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for brand in os.listdir('/home/l/liny/ruofan/lightly/datasets/targetlist/test/'):\n",
    "#     os.makedirs(os.path.join('/home/l/liny/ruofan/lightly/datasets/targetlist-merge/', brand), exist_ok=True)\n",
    "#     for file in os.listdir(os.path.join('/home/l/liny/ruofan/lightly/datasets/targetlist/test/', brand)):\n",
    "#         shutil.copyfile(os.path.join('/home/l/liny/ruofan/lightly/datasets/targetlist/test/', brand, file),\n",
    "#                        os.path.join('/home/l/liny/ruofan/lightly/datasets/targetlist-merge/', brand, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Importing packages in single_experiment_runner\n",
      "INFO:root:Importing packages in base_runner\n",
      "INFO:root:Done importing packages in base_runner\n",
      "INFO:root:Done importing packages in single_experiment_runner\n",
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "INFO:faiss.loader:Loading faiss.\n",
      "INFO:faiss.loader:Successfully loaded faiss.\n",
      "INFO:root:NUMPY_RANDOM = RandomState(MT19937)\n",
      "None\n",
      "INFO:root:train transform: Compose(\n",
      "    ConvertToBGR()\n",
      "    Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
      "    RandomResizedCrop(size=(227, 227), scale=(0.16, 1), ratio=(0.75, 1.33), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ToTensor()\n",
      "    Multiplier(multiple=255)\n",
      "    Normalize(mean=[104, 117, 128], std=[1, 1, 1])\n",
      ")\n",
      "INFO:root:eval transform: Compose(\n",
      "    ConvertToBGR()\n",
      "    Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
      "    CenterCrop(size=(227, 227))\n",
      "    ToTensor()\n",
      "    Multiplier(multiple=255)\n",
      "    Normalize(mean=[104, 117, 128], std=[1, 1, 1])\n",
      ")\n",
      "INFO:root:Asserted: the ['test'] set indices are equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['train'] set indices are not_equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['val'] set indices are not_equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['train', 'val', 'test'] set indices are disjoint within split_scheme_names\n",
      "INFO:root:Asserted: the ['test'] set indices are equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['train'] set indices are not_equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['val'] set indices are not_equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['train', 'val', 'test'] set indices are disjoint within split_scheme_names\n",
      "INFO:root:Asserted: the ['train', 'val', 'test'] set indices are equal across transform_types\n",
      "INFO:root:Asserted: the ['val'] set indices are disjoint across split_scheme_names\n",
      "INFO:root:Asserted: the ['val'] set indices are disjoint across split_scheme_names\n",
      "INFO:root:Asserted: the ['train', 'val', 'test'] set class labels are disjoint within split_scheme_names\n",
      "INFO:root:Asserted: the ['train', 'val', 'test'] set class labels are disjoint within split_scheme_names\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:trunk_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:embedder_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_0 / train / length 1223 / using train transform\n",
      "INFO:root:Creating end_of_epoch_hook\n",
      "INFO:root:Getting split: Test50_50_Partitions4_0 / val / length 461 / using eval transform\n",
      "INFO:root:Launching evaluation for model untrained_trunk\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:Getting split: Test50_50_Partitions4_0 / val / length 461 / using eval transform\n",
      "INFO:root:Evaluating epoch -1\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:14<00:00,  1.05it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 1024\n",
      "INFO:root:Launching evaluation for model untrained_trunk_and_embedder\n",
      "INFO:root:Using input models for evaluation\n",
      "INFO:root:Getting split: Test50_50_Partitions4_0 / val / length 461 / using eval transform\n",
      "INFO:root:Evaluating epoch 0\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:11,  1.09it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:05<00:00,  2.51it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:Initializing dataloader\n",
      "INFO:root:Initializing dataloader iterator\n",
      "INFO:root:Done creating dataloader iterator\n",
      "INFO:root:TRAINING EPOCH 1\n",
      "total_loss=6.41965:   1%|▏                      | 1/100 [00:00<01:32,  1.07it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "total_loss=5.60397:  16%|███▌                  | 16/100 [00:14<00:50,  1.66it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "total_loss=4.70550: 100%|█████████████████████| 100/100 [01:10<00:00,  1.41it/s]\n",
      "INFO:root:TRAINING EPOCH 2\n",
      "total_loss=4.25509: 100%|█████████████████████| 100/100 [01:02<00:00,  1.61it/s]\n",
      "INFO:root:Evaluating epoch 2\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "  7%|██▉                                         | 1/15 [00:00<00:12,  1.15it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:04<00:00,  3.03it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 3\n",
      "total_loss=3.56658: 100%|█████████████████████| 100/100 [01:25<00:00,  1.16it/s]\n",
      "INFO:root:TRAINING EPOCH 4\n",
      "total_loss=3.23117: 100%|█████████████████████| 100/100 [01:17<00:00,  1.28it/s]\n",
      "INFO:root:Evaluating epoch 4\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:07,  1.68it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [00:05<00:00,  2.64it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 5\n",
      "total_loss=3.21627: 100%|█████████████████████| 100/100 [00:57<00:00,  1.75it/s]\n",
      "INFO:root:TRAINING EPOCH 6\n",
      "total_loss=2.64234: 100%|█████████████████████| 100/100 [01:12<00:00,  1.37it/s]\n",
      "INFO:root:Evaluating epoch 6\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:08,  1.54it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:05<00:00,  2.70it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.7093275488069414\n",
      "INFO:root:TRAINING EPOCH 7\n",
      "total_loss=1.36518: 100%|█████████████████████| 100/100 [01:15<00:00,  1.33it/s]\n",
      "INFO:root:TRAINING EPOCH 8\n",
      "total_loss=1.30289: 100%|█████████████████████| 100/100 [01:07<00:00,  1.47it/s]\n",
      "INFO:root:Evaluating epoch 8\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:13,  1.00s/it]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:06<00:00,  2.46it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.720173535791757\n",
      "INFO:root:TRAINING EPOCH 9\n",
      "total_loss=1.73433: 100%|█████████████████████| 100/100 [00:55<00:00,  1.81it/s]\n",
      "INFO:root:TRAINING EPOCH 10\n",
      "total_loss=0.98464: 100%|█████████████████████| 100/100 [01:10<00:00,  1.42it/s]\n",
      "INFO:root:Evaluating epoch 10\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:07,  1.63it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:07<00:00,  1.98it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.7288503253796096\n",
      "INFO:root:TRAINING EPOCH 11\n",
      "total_loss=0.47226: 100%|█████████████████████| 100/100 [01:07<00:00,  1.49it/s]\n",
      "INFO:root:TRAINING EPOCH 12\n",
      "total_loss=1.10824: 100%|█████████████████████| 100/100 [01:04<00:00,  1.55it/s]\n",
      "INFO:root:Evaluating epoch 12\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "  7%|██▉                                         | 1/15 [00:00<00:11,  1.21it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:05<00:00,  2.61it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.7483731019522777\n",
      "INFO:root:TRAINING EPOCH 13\n",
      "total_loss=0.57987: 100%|█████████████████████| 100/100 [01:01<00:00,  1.63it/s]\n",
      "INFO:root:TRAINING EPOCH 14\n",
      "total_loss=1.04543: 100%|█████████████████████| 100/100 [01:23<00:00,  1.20it/s]\n",
      "INFO:root:Evaluating epoch 14\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 20%|████████▊                                   | 3/15 [00:02<00:10,  1.15it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:06<00:00,  2.36it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.7635574837310195\n",
      "INFO:root:TRAINING EPOCH 15\n",
      "total_loss=0.35802: 100%|█████████████████████| 100/100 [01:19<00:00,  1.26it/s]\n",
      "INFO:root:TRAINING EPOCH 16\n",
      "total_loss=0.64326: 100%|█████████████████████| 100/100 [01:16<00:00,  1.30it/s]\n",
      "INFO:root:Evaluating epoch 16\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:07,  1.69it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:05<00:00,  2.82it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 17\n",
      "total_loss=0.32264: 100%|█████████████████████| 100/100 [01:13<00:00,  1.36it/s]\n",
      "INFO:root:TRAINING EPOCH 18\n",
      "total_loss=0.23072: 100%|█████████████████████| 100/100 [01:10<00:00,  1.43it/s]\n",
      "INFO:root:Evaluating epoch 18\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:09,  1.32it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [00:05<00:00,  2.62it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 19\n",
      "total_loss=0.41894: 100%|█████████████████████| 100/100 [01:12<00:00,  1.38it/s]\n",
      "INFO:root:TRAINING EPOCH 20\n",
      "total_loss=0.25055: 100%|█████████████████████| 100/100 [00:46<00:00,  2.15it/s]\n",
      "INFO:root:Evaluating epoch 20\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:06,  2.05it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:04<00:00,  3.11it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.7700650759219089\n",
      "INFO:root:TRAINING EPOCH 21\n",
      "total_loss=0.41090: 100%|█████████████████████| 100/100 [00:46<00:00,  2.17it/s]\n",
      "INFO:root:Evaluating epoch 22\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:06,  1.90it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:05<00:00,  2.99it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 23\n",
      "total_loss=0.15691: 100%|█████████████████████| 100/100 [00:39<00:00,  2.51it/s]\n",
      "INFO:root:TRAINING EPOCH 24\n",
      "total_loss=0.27088: 100%|█████████████████████| 100/100 [00:50<00:00,  1.99it/s]\n",
      "INFO:root:Evaluating epoch 24\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 20%|████████▊                                   | 3/15 [00:03<00:15,  1.31s/it]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:06<00:00,  2.31it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 25\n",
      "total_loss=0.13379: 100%|█████████████████████| 100/100 [00:35<00:00,  2.81it/s]\n",
      "INFO:root:TRAINING EPOCH 26\n",
      "total_loss=0.17577: 100%|█████████████████████| 100/100 [00:35<00:00,  2.83it/s]\n",
      "INFO:root:Evaluating epoch 26\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 27%|███████████▋                                | 4/15 [00:02<00:03,  2.81it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:04<00:00,  3.20it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 27\n",
      "total_loss=0.21669: 100%|█████████████████████| 100/100 [00:32<00:00,  3.08it/s]\n",
      "INFO:root:TRAINING EPOCH 28\n",
      "total_loss=0.19588: 100%|█████████████████████| 100/100 [00:40<00:00,  2.48it/s]\n",
      "INFO:root:Evaluating epoch 28\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:06,  2.07it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  4.22it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 29\n",
      "total_loss=0.09126: 100%|█████████████████████| 100/100 [00:49<00:00,  2.02it/s]\n",
      "INFO:root:TRAINING EPOCH 30\n",
      "total_loss=0.10593: 100%|█████████████████████| 100/100 [00:44<00:00,  2.24it/s]\n",
      "INFO:root:Evaluating epoch 30\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "  7%|██▉                                         | 1/15 [00:00<00:08,  1.64it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:04<00:00,  3.02it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 31\n",
      "total_loss=0.12279: 100%|█████████████████████| 100/100 [00:41<00:00,  2.44it/s]\n",
      "INFO:root:TRAINING EPOCH 32\n",
      "total_loss=0.09498:  19%|████▏                 | 19/100 [00:09<00:39,  2.03it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "total_loss=0.11598:  20%|████▍                 | 20/100 [00:09<00:32,  2.43it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "total_loss=0.08310: 100%|█████████████████████| 100/100 [00:33<00:00,  3.00it/s]\n",
      "INFO:root:Evaluating epoch 32\n",
      "INFO:root:Getting embeddings for the val split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:10,  1.24it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:04<00:00,  3.52it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 33\n",
      "total_loss=0.10962: 100%|█████████████████████| 100/100 [00:33<00:00,  3.02it/s]\n",
      "INFO:root:TRAINING EPOCH 34\n",
      "total_loss=0.13731: 100%|█████████████████████| 100/100 [00:34<00:00,  2.90it/s]\n",
      "INFO:root:Evaluating epoch 34\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:07,  1.79it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  4.05it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 35\n",
      "total_loss=0.18424: 100%|█████████████████████| 100/100 [00:51<00:00,  1.93it/s]\n",
      "INFO:root:TRAINING EPOCH 36\n",
      "total_loss=0.06097: 100%|█████████████████████| 100/100 [00:48<00:00,  2.08it/s]\n",
      "INFO:root:Evaluating epoch 36\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:06,  2.01it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  3.94it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.7722342733188721\n",
      "INFO:root:TRAINING EPOCH 37\n",
      "total_loss=0.04237: 100%|█████████████████████| 100/100 [00:47<00:00,  2.10it/s]\n",
      "INFO:root:TRAINING EPOCH 38\n",
      "total_loss=0.02522: 100%|█████████████████████| 100/100 [00:45<00:00,  2.22it/s]\n",
      "INFO:root:Evaluating epoch 38\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:06,  2.05it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  3.82it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.7787418655097614\n",
      "INFO:root:TRAINING EPOCH 39\n",
      "total_loss=0.03209: 100%|█████████████████████| 100/100 [00:36<00:00,  2.77it/s]\n",
      "INFO:root:TRAINING EPOCH 40\n",
      "total_loss=0.27093: 100%|█████████████████████| 100/100 [00:37<00:00,  2.68it/s]\n",
      "INFO:root:Evaluating epoch 40\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:06,  2.14it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:05<00:00,  2.90it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 41\n",
      "total_loss=0.01936: 100%|█████████████████████| 100/100 [00:45<00:00,  2.18it/s]\n",
      "INFO:root:TRAINING EPOCH 42\n",
      "total_loss=0.03770: 100%|█████████████████████| 100/100 [00:42<00:00,  2.34it/s]\n",
      "INFO:root:Evaluating epoch 42\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:06,  1.95it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  3.75it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 43\n",
      "total_loss=0.04577: 100%|█████████████████████| 100/100 [00:42<00:00,  2.33it/s]\n",
      "INFO:root:TRAINING EPOCH 44\n",
      "total_loss=0.05563: 100%|█████████████████████| 100/100 [00:42<00:00,  2.34it/s]\n",
      "INFO:root:Evaluating epoch 44\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:06,  1.99it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  4.25it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 45\n",
      "total_loss=0.07364: 100%|█████████████████████| 100/100 [00:36<00:00,  2.71it/s]\n",
      "INFO:root:TRAINING EPOCH 46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss=0.07765: 100%|█████████████████████| 100/100 [00:35<00:00,  2.81it/s]\n",
      "INFO:root:Evaluating epoch 46\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 20%|████████▊                                   | 3/15 [00:01<00:03,  3.42it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  4.06it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8004338394793926\n",
      "INFO:root:TRAINING EPOCH 47\n",
      "total_loss=0.04854: 100%|█████████████████████| 100/100 [00:46<00:00,  2.16it/s]\n",
      "INFO:root:TRAINING EPOCH 48\n",
      "total_loss=0.05072: 100%|█████████████████████| 100/100 [00:39<00:00,  2.51it/s]\n",
      "INFO:root:Evaluating epoch 48\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 27%|███████████▋                                | 4/15 [00:02<00:03,  2.78it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:04<00:00,  3.21it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 49\n",
      "total_loss=0.08157: 100%|█████████████████████| 100/100 [00:44<00:00,  2.23it/s]\n",
      "INFO:root:TRAINING EPOCH 50\n",
      "total_loss=0.02492: 100%|█████████████████████| 100/100 [00:43<00:00,  2.28it/s]\n",
      "INFO:root:Evaluating epoch 50\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 13%|█████▊                                      | 2/15 [00:01<00:08,  1.58it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  3.76it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:Deleted self.models\n",
      "INFO:root:Deleted self.sampler\n",
      "INFO:root:Deleted self.loss_funcs\n",
      "INFO:root:Deleted self.mining_funcs\n",
      "INFO:root:Deleted self.optimizers\n",
      "INFO:root:Deleted self.lr_schedulers\n",
      "INFO:root:Deleted self.gradient_clippers\n",
      "INFO:root:Deleted self.record_keeper\n",
      "INFO:root:Deleted self.hooks\n",
      "INFO:root:Deleted self.trainer\n",
      "INFO:root:Deleted self.tester\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:trunk_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:embedder_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_1 / train / length 1224 / using train transform\n",
      "INFO:root:Creating end_of_epoch_hook\n",
      "INFO:root:Getting split: Test50_50_Partitions4_1 / val / length 460 / using eval transform\n",
      "INFO:root:Launching evaluation for model untrained_trunk\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:Getting split: Test50_50_Partitions4_1 / val / length 460 / using eval transform\n",
      "INFO:root:Evaluating epoch -1\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  7.41it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:05<00:00,  2.79it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 1024\n",
      "INFO:root:Launching evaluation for model untrained_trunk_and_embedder\n",
      "INFO:root:Using input models for evaluation\n",
      "INFO:root:Getting split: Test50_50_Partitions4_1 / val / length 460 / using eval transform\n",
      "INFO:root:Evaluating epoch 0\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  7.34it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  4.43it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:Initializing dataloader\n",
      "INFO:root:Initializing dataloader iterator\n",
      "INFO:root:Done creating dataloader iterator\n",
      "INFO:root:TRAINING EPOCH 1\n",
      "total_loss=6.22856:  10%|██▏                   | 10/100 [00:02<00:20,  4.30it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "total_loss=6.23535:  11%|██▍                   | 11/100 [00:02<00:20,  4.36it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "total_loss=4.52006: 100%|█████████████████████| 100/100 [00:51<00:00,  1.94it/s]\n",
      "INFO:root:TRAINING EPOCH 2\n",
      "total_loss=3.25776: 100%|█████████████████████| 100/100 [00:33<00:00,  2.96it/s]\n",
      "INFO:root:Evaluating epoch 2\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  8.12it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  4.12it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.7695652173913043\n",
      "INFO:root:TRAINING EPOCH 3\n",
      "total_loss=2.69012: 100%|█████████████████████| 100/100 [00:43<00:00,  2.31it/s]\n",
      "INFO:root:TRAINING EPOCH 4\n",
      "total_loss=3.63489: 100%|█████████████████████| 100/100 [00:44<00:00,  2.23it/s]\n",
      "INFO:root:Evaluating epoch 4\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  7.84it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:06<00:00,  2.26it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.7760869565217391\n",
      "INFO:root:TRAINING EPOCH 5\n",
      "total_loss=2.09118: 100%|█████████████████████| 100/100 [00:54<00:00,  1.85it/s]\n",
      "INFO:root:TRAINING EPOCH 6\n",
      "total_loss=1.61835: 100%|█████████████████████| 100/100 [00:42<00:00,  2.36it/s]\n",
      "INFO:root:Evaluating epoch 6\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:00,  6.14it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  3.88it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8152173913043478\n",
      "INFO:root:TRAINING EPOCH 7\n",
      "total_loss=1.20373: 100%|█████████████████████| 100/100 [00:36<00:00,  2.72it/s]\n",
      "INFO:root:TRAINING EPOCH 8\n",
      "total_loss=0.90646: 100%|█████████████████████| 100/100 [00:34<00:00,  2.88it/s]\n",
      "INFO:root:Evaluating epoch 8\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  6.92it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  4.43it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 9\n",
      "total_loss=0.81068: 100%|█████████████████████| 100/100 [00:46<00:00,  2.15it/s]\n",
      "INFO:root:TRAINING EPOCH 10\n",
      "total_loss=1.00598: 100%|█████████████████████| 100/100 [00:43<00:00,  2.32it/s]\n",
      "INFO:root:Evaluating epoch 10\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:00,  6.27it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  3.96it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8173913043478261\n",
      "INFO:root:TRAINING EPOCH 11\n",
      "total_loss=0.89845: 100%|█████████████████████| 100/100 [00:46<00:00,  2.16it/s]\n",
      "INFO:root:TRAINING EPOCH 12\n",
      "total_loss=1.02879: 100%|█████████████████████| 100/100 [00:38<00:00,  2.61it/s]\n",
      "INFO:root:Evaluating epoch 12\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  7.44it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  4.27it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8478260869565217\n",
      "INFO:root:TRAINING EPOCH 13\n",
      "total_loss=1.20915: 100%|█████████████████████| 100/100 [00:31<00:00,  3.21it/s]\n",
      "INFO:root:TRAINING EPOCH 14\n",
      "total_loss=0.70388: 100%|█████████████████████| 100/100 [00:32<00:00,  3.12it/s]\n",
      "INFO:root:Evaluating epoch 14\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  5.66it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  3.81it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8521739130434782\n",
      "INFO:root:TRAINING EPOCH 15\n",
      "total_loss=0.46313: 100%|█████████████████████| 100/100 [00:37<00:00,  2.67it/s]\n",
      "INFO:root:TRAINING EPOCH 16\n",
      "total_loss=0.34437: 100%|█████████████████████| 100/100 [00:39<00:00,  2.51it/s]\n",
      "INFO:root:Evaluating epoch 16\n",
      "INFO:root:Getting embeddings for the val split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:02<00:00,  6.49it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:05<00:00,  2.89it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 17\n",
      "total_loss=0.14828: 100%|█████████████████████| 100/100 [00:44<00:00,  2.27it/s]\n",
      "INFO:root:TRAINING EPOCH 18\n",
      "total_loss=0.55584: 100%|█████████████████████| 100/100 [00:41<00:00,  2.39it/s]\n",
      "INFO:root:Evaluating epoch 18\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:00,  6.33it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:04<00:00,  3.25it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 19\n",
      "total_loss=0.20633: 100%|█████████████████████| 100/100 [00:39<00:00,  2.55it/s]\n",
      "INFO:root:TRAINING EPOCH 20\n",
      "total_loss=0.99762: 100%|█████████████████████| 100/100 [00:32<00:00,  3.11it/s]\n",
      "INFO:root:Evaluating epoch 20\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  7.57it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  4.16it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 21\n",
      "total_loss=0.15401: 100%|█████████████████████| 100/100 [00:44<00:00,  2.25it/s]\n",
      "INFO:root:Evaluating epoch 24\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  7.90it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:05<00:00,  2.93it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8652173913043478\n",
      "INFO:root:TRAINING EPOCH 25\n",
      "total_loss=0.23895: 100%|█████████████████████| 100/100 [00:43<00:00,  2.30it/s]\n",
      "INFO:root:TRAINING EPOCH 26\n",
      "total_loss=0.21275: 100%|█████████████████████| 100/100 [00:37<00:00,  2.69it/s]\n",
      "INFO:root:Evaluating epoch 26\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:00,  6.19it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:09<00:00,  1.63it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 27\n",
      "total_loss=0.27580: 100%|█████████████████████| 100/100 [00:39<00:00,  2.53it/s]\n",
      "INFO:root:TRAINING EPOCH 28\n",
      "total_loss=0.20563: 100%|█████████████████████| 100/100 [00:42<00:00,  2.34it/s]\n",
      "INFO:root:Evaluating epoch 28\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  7.63it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  4.30it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8782608695652174\n",
      "INFO:root:TRAINING EPOCH 29\n",
      "total_loss=0.26896: 100%|█████████████████████| 100/100 [00:46<00:00,  2.16it/s]\n",
      "INFO:root:TRAINING EPOCH 30\n",
      "total_loss=0.13101: 100%|█████████████████████| 100/100 [00:48<00:00,  2.08it/s]\n",
      "INFO:root:Evaluating epoch 30\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 67%|████████████████████████████▋              | 10/15 [00:03<00:01,  2.89it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:05<00:00,  2.98it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 31\n",
      "total_loss=0.10968: 100%|█████████████████████| 100/100 [00:41<00:00,  2.39it/s]\n",
      "INFO:root:TRAINING EPOCH 32\n",
      "total_loss=0.11188:  15%|███▎                  | 15/100 [00:03<00:20,  4.16it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss=0.03814:  19%|████▏                 | 19/100 [00:06<00:37,  2.15it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "total_loss=0.25598: 100%|█████████████████████| 100/100 [00:29<00:00,  3.38it/s]\n",
      "INFO:root:Evaluating epoch 32\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  7.75it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  4.40it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 33\n",
      "total_loss=0.39702: 100%|█████████████████████| 100/100 [00:32<00:00,  3.12it/s]\n",
      "INFO:root:TRAINING EPOCH 34\n",
      "total_loss=0.11931: 100%|█████████████████████| 100/100 [00:33<00:00,  2.98it/s]\n",
      "INFO:root:Evaluating epoch 34\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:02<00:01,  5.78it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:04<00:00,  3.65it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 35\n",
      "total_loss=0.08974: 100%|█████████████████████| 100/100 [00:40<00:00,  2.50it/s]\n",
      "INFO:root:TRAINING EPOCH 36\n",
      "total_loss=0.14666: 100%|█████████████████████| 100/100 [00:40<00:00,  2.48it/s]\n",
      "INFO:root:Evaluating epoch 36\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  6.89it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:05<00:00,  2.78it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 37\n",
      "total_loss=0.05815: 100%|█████████████████████| 100/100 [00:38<00:00,  2.59it/s]\n",
      "INFO:root:TRAINING EPOCH 38\n",
      "total_loss=0.05840: 100%|█████████████████████| 100/100 [00:38<00:00,  2.58it/s]\n",
      "INFO:root:Evaluating epoch 38\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:03<00:02,  2.61it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 39\n",
      "total_loss=0.16525: 100%|█████████████████████| 100/100 [00:29<00:00,  3.40it/s]\n",
      "INFO:root:TRAINING EPOCH 40\n",
      "total_loss=0.04362: 100%|█████████████████████| 100/100 [00:33<00:00,  2.95it/s]\n",
      "INFO:root:Evaluating epoch 40\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  7.59it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  4.29it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 41\n",
      "total_loss=0.06463: 100%|█████████████████████| 100/100 [00:34<00:00,  2.92it/s]\n",
      "INFO:root:TRAINING EPOCH 42\n",
      "total_loss=0.04806: 100%|█████████████████████| 100/100 [00:43<00:00,  2.31it/s]\n",
      "INFO:root:Evaluating epoch 42\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 67%|████████████████████████████▋              | 10/15 [00:02<00:00,  5.97it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:05<00:00,  2.85it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 43\n",
      "total_loss=0.01038: 100%|█████████████████████| 100/100 [00:37<00:00,  2.64it/s]\n",
      "INFO:root:TRAINING EPOCH 44\n",
      "total_loss=0.29391: 100%|█████████████████████| 100/100 [00:38<00:00,  2.58it/s]\n",
      "INFO:root:Evaluating epoch 44\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  6.86it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [00:06<00:00,  2.45it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 45\n",
      "total_loss=0.05557: 100%|█████████████████████| 100/100 [00:48<00:00,  2.06it/s]\n",
      "INFO:root:TRAINING EPOCH 46\n",
      "total_loss=0.01954: 100%|█████████████████████| 100/100 [00:31<00:00,  3.17it/s]\n",
      "INFO:root:Evaluating epoch 46\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:00,  7.05it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  4.67it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 47\n",
      "total_loss=0.02673: 100%|█████████████████████| 100/100 [00:33<00:00,  2.96it/s]\n",
      "INFO:root:TRAINING EPOCH 48\n",
      "total_loss=0.01894: 100%|█████████████████████| 100/100 [00:35<00:00,  2.84it/s]\n",
      "INFO:root:Evaluating epoch 48\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  7.43it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 15/15 [00:03<00:00,  4.01it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 49\n",
      "total_loss=0.25522: 100%|█████████████████████| 100/100 [00:44<00:00,  2.23it/s]\n",
      "INFO:root:TRAINING EPOCH 50\n",
      "total_loss=0.01930:  28%|██████▏               | 28/100 [00:20<00:48,  1.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss=0.20081: 100%|█████████████████████| 100/100 [00:36<00:00,  2.71it/s]\n",
      "INFO:root:Evaluating epoch 36\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  8%|███▍                                        | 1/13 [00:00<00:06,  1.96it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 13/13 [00:02<00:00,  5.04it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 37\n",
      "total_loss=0.06570: 100%|█████████████████████| 100/100 [00:34<00:00,  2.92it/s]\n",
      "INFO:root:TRAINING EPOCH 38\n",
      "total_loss=0.17965: 100%|█████████████████████| 100/100 [00:34<00:00,  2.88it/s]\n",
      "INFO:root:Evaluating epoch 38\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  8%|███▍                                        | 1/13 [00:00<00:06,  1.74it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 13/13 [00:02<00:00,  5.14it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 39\n",
      "total_loss=0.02184: 100%|█████████████████████| 100/100 [00:42<00:00,  2.37it/s]\n",
      "INFO:root:TRAINING EPOCH 40\n",
      "total_loss=0.03223: 100%|█████████████████████| 100/100 [00:39<00:00,  2.56it/s]\n",
      "INFO:root:Evaluating epoch 40\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  8%|███▍                                        | 1/13 [00:00<00:06,  1.84it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 13/13 [00:07<00:00,  1.64it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.890818858560794\n",
      "INFO:root:TRAINING EPOCH 41\n",
      "total_loss=0.07003: 100%|█████████████████████| 100/100 [00:46<00:00,  2.13it/s]\n",
      "INFO:root:TRAINING EPOCH 42\n",
      "total_loss=0.32965: 100%|█████████████████████| 100/100 [00:38<00:00,  2.61it/s]\n",
      "INFO:root:Evaluating epoch 42\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  8%|███▍                                        | 1/13 [00:00<00:06,  1.99it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.06it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 43\n",
      "total_loss=0.01466: 100%|█████████████████████| 100/100 [00:36<00:00,  2.76it/s]\n",
      "INFO:root:TRAINING EPOCH 44\n",
      "total_loss=0.03392: 100%|█████████████████████| 100/100 [00:35<00:00,  2.79it/s]\n",
      "INFO:root:Evaluating epoch 44\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  8%|███▍                                        | 1/13 [00:00<00:06,  1.94it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 13/13 [00:02<00:00,  5.05it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 45\n",
      "total_loss=0.02086: 100%|█████████████████████| 100/100 [00:45<00:00,  2.18it/s]\n",
      "INFO:root:TRAINING EPOCH 46\n",
      "total_loss=0.09602: 100%|█████████████████████| 100/100 [00:39<00:00,  2.50it/s]\n",
      "INFO:root:Evaluating epoch 46\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  8%|███▍                                        | 1/13 [00:00<00:06,  1.81it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 13/13 [00:05<00:00,  2.49it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 47\n",
      "total_loss=0.02142: 100%|█████████████████████| 100/100 [00:44<00:00,  2.23it/s]\n",
      "INFO:root:TRAINING EPOCH 48\n",
      "total_loss=0.01511: 100%|█████████████████████| 100/100 [00:41<00:00,  2.41it/s]\n",
      "INFO:root:Evaluating epoch 48\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  8%|███▍                                        | 1/13 [00:00<00:06,  1.80it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 13/13 [00:02<00:00,  5.07it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 49\n",
      "total_loss=0.09506: 100%|█████████████████████| 100/100 [00:39<00:00,  2.53it/s]\n",
      "INFO:root:TRAINING EPOCH 50\n",
      "total_loss=0.03016: 100%|█████████████████████| 100/100 [00:36<00:00,  2.71it/s]\n",
      "INFO:root:Evaluating epoch 50\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  8%|███▍                                        | 1/13 [00:00<00:06,  1.86it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 13/13 [00:03<00:00,  4.09it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:Deleted self.models\n",
      "INFO:root:Deleted self.sampler\n",
      "INFO:root:Deleted self.loss_funcs\n",
      "INFO:root:Deleted self.mining_funcs\n",
      "INFO:root:Deleted self.optimizers\n",
      "INFO:root:Deleted self.lr_schedulers\n",
      "INFO:root:Deleted self.gradient_clippers\n",
      "INFO:root:Deleted self.record_keeper\n",
      "INFO:root:Deleted self.hooks\n",
      "INFO:root:Deleted self.trainer\n",
      "INFO:root:Deleted self.tester\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:trunk_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:embedder_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_3 / train / length 1324 / using train transform\n",
      "INFO:root:Creating end_of_epoch_hook\n",
      "INFO:root:Getting split: Test50_50_Partitions4_3 / val / length 360 / using eval transform\n",
      "INFO:root:Launching evaluation for model untrained_trunk\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:Getting split: Test50_50_Partitions4_3 / val / length 360 / using eval transform\n",
      "INFO:root:Evaluating epoch -1\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25%|███████████                                 | 3/12 [00:00<00:01,  4.78it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:04<00:00,  2.73it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 1024\n",
      "INFO:root:Launching evaluation for model untrained_trunk_and_embedder\n",
      "INFO:root:Using input models for evaluation\n",
      "INFO:root:Getting split: Test50_50_Partitions4_3 / val / length 360 / using eval transform\n",
      "INFO:root:Evaluating epoch 0\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:01,  4.56it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:03<00:00,  3.39it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:Initializing dataloader\n",
      "INFO:root:Initializing dataloader iterator\n",
      "INFO:root:Done creating dataloader iterator\n",
      "INFO:root:TRAINING EPOCH 1\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "total_loss=6.20519:  11%|██▍                   | 11/100 [00:05<00:30,  2.93it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "total_loss=5.31467: 100%|█████████████████████| 100/100 [00:32<00:00,  3.06it/s]\n",
      "INFO:root:TRAINING EPOCH 2\n",
      "total_loss=2.91626: 100%|█████████████████████| 100/100 [00:30<00:00,  3.30it/s]\n",
      "INFO:root:Evaluating epoch 2\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:01,  4.55it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:03<00:00,  3.39it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8027777777777778\n",
      "INFO:root:TRAINING EPOCH 3\n",
      "total_loss=2.67303: 100%|█████████████████████| 100/100 [00:39<00:00,  2.56it/s]\n",
      "INFO:root:TRAINING EPOCH 4\n",
      "total_loss=1.86871: 100%|█████████████████████| 100/100 [00:38<00:00,  2.58it/s]\n",
      "INFO:root:Evaluating epoch 4\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 17%|███████▎                                    | 2/12 [00:00<00:03,  2.95it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:05<00:00,  2.13it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.825\n",
      "INFO:root:TRAINING EPOCH 5\n",
      "total_loss=1.22420: 100%|█████████████████████| 100/100 [00:39<00:00,  2.56it/s]\n",
      "INFO:root:TRAINING EPOCH 6\n",
      "total_loss=1.57833: 100%|█████████████████████| 100/100 [00:37<00:00,  2.64it/s]\n",
      "INFO:root:Evaluating epoch 6\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  8%|███▋                                        | 1/12 [00:02<00:26,  2.40s/it]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:08<00:00,  1.41it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8361111111111111\n",
      "INFO:root:TRAINING EPOCH 7\n",
      "total_loss=1.73193: 100%|█████████████████████| 100/100 [00:31<00:00,  3.18it/s]\n",
      "INFO:root:TRAINING EPOCH 8\n",
      "total_loss=1.48342: 100%|█████████████████████| 100/100 [00:32<00:00,  3.09it/s]\n",
      "INFO:root:Evaluating epoch 8\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:02,  4.17it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:03<00:00,  3.42it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8388888888888889\n",
      "INFO:root:TRAINING EPOCH 9\n",
      "total_loss=0.70781: 100%|█████████████████████| 100/100 [00:30<00:00,  3.31it/s]\n",
      "INFO:root:TRAINING EPOCH 10\n",
      "total_loss=0.75471: 100%|█████████████████████| 100/100 [00:29<00:00,  3.37it/s]\n",
      "INFO:root:Evaluating epoch 10\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 17%|███████▎                                    | 2/12 [00:00<00:03,  2.95it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 12/12 [00:04<00:00,  2.90it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.85\n",
      "INFO:root:TRAINING EPOCH 11\n",
      "total_loss=0.85232: 100%|█████████████████████| 100/100 [00:38<00:00,  2.57it/s]\n",
      "INFO:root:TRAINING EPOCH 12\n",
      "total_loss=1.29564: 100%|█████████████████████| 100/100 [00:42<00:00,  2.33it/s]\n",
      "INFO:root:Evaluating epoch 12\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 17%|███████▎                                    | 2/12 [00:00<00:03,  2.84it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:04<00:00,  2.72it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 13\n",
      "total_loss=0.89688: 100%|█████████████████████| 100/100 [00:55<00:00,  1.80it/s]\n",
      "INFO:root:TRAINING EPOCH 14\n",
      "total_loss=0.91007: 100%|█████████████████████| 100/100 [00:39<00:00,  2.54it/s]\n",
      "INFO:root:Evaluating epoch 14\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:01<00:04,  2.23it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:05<00:00,  2.26it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8555555555555555\n",
      "INFO:root:TRAINING EPOCH 15\n",
      "total_loss=0.39718: 100%|█████████████████████| 100/100 [00:33<00:00,  2.95it/s]\n",
      "INFO:root:TRAINING EPOCH 16\n",
      "total_loss=0.16594: 100%|█████████████████████| 100/100 [00:32<00:00,  3.04it/s]\n",
      "INFO:root:Evaluating epoch 16\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:02,  4.16it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:03<00:00,  3.16it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8666666666666667\n",
      "INFO:root:TRAINING EPOCH 17\n",
      "total_loss=0.28715: 100%|█████████████████████| 100/100 [00:41<00:00,  2.39it/s]\n",
      "INFO:root:TRAINING EPOCH 18\n",
      "total_loss=0.17455: 100%|█████████████████████| 100/100 [00:39<00:00,  2.54it/s]\n",
      "INFO:root:Evaluating epoch 18\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:01,  4.69it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:11<00:00,  1.01it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 19\n",
      "total_loss=0.33849: 100%|█████████████████████| 100/100 [00:39<00:00,  2.50it/s]\n",
      "INFO:root:TRAINING EPOCH 20\n",
      "total_loss=0.25950: 100%|█████████████████████| 100/100 [00:34<00:00,  2.87it/s]\n",
      "INFO:root:Evaluating epoch 20\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:02,  4.33it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:03<00:00,  3.29it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.875\n",
      "INFO:root:TRAINING EPOCH 21\n",
      "total_loss=0.33534: 100%|█████████████████████| 100/100 [00:31<00:00,  3.19it/s]\n",
      "INFO:root:TRAINING EPOCH 22\n",
      "total_loss=0.14273: 100%|█████████████████████| 100/100 [00:29<00:00,  3.44it/s]\n",
      "INFO:root:Evaluating epoch 22\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:02,  4.33it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:04<00:00,  2.76it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 23\n",
      "total_loss=0.25112: 100%|█████████████████████| 100/100 [00:32<00:00,  3.11it/s]\n",
      "INFO:root:TRAINING EPOCH 24\n",
      "total_loss=0.04470: 100%|█████████████████████| 100/100 [00:30<00:00,  3.31it/s]\n",
      "INFO:root:Evaluating epoch 24\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:02,  4.08it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 12/12 [00:06<00:00,  1.75it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 25\n",
      "total_loss=0.23839: 100%|█████████████████████| 100/100 [00:36<00:00,  2.73it/s]\n",
      "INFO:root:TRAINING EPOCH 26\n",
      "total_loss=0.16511: 100%|█████████████████████| 100/100 [00:33<00:00,  2.97it/s]\n",
      "INFO:root:Evaluating epoch 26\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:02,  4.04it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:03<00:00,  3.07it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8805555555555555\n",
      "INFO:root:TRAINING EPOCH 27\n",
      "total_loss=0.17461: 100%|█████████████████████| 100/100 [00:38<00:00,  2.61it/s]\n",
      "INFO:root:TRAINING EPOCH 28\n",
      "total_loss=0.30408: 100%|█████████████████████| 100/100 [00:38<00:00,  2.61it/s]\n",
      "INFO:root:Evaluating epoch 28\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 17%|███████▎                                    | 2/12 [00:00<00:03,  2.86it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:03<00:00,  3.32it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8833333333333333\n",
      "INFO:root:TRAINING EPOCH 29\n",
      "total_loss=0.04342: 100%|█████████████████████| 100/100 [00:30<00:00,  3.23it/s]\n",
      "INFO:root:TRAINING EPOCH 30\n",
      "total_loss=0.28709: 100%|█████████████████████| 100/100 [00:31<00:00,  3.13it/s]\n",
      "INFO:root:Evaluating epoch 30\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:02,  4.47it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:03<00:00,  3.15it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8888888888888888\n",
      "INFO:root:TRAINING EPOCH 31\n",
      "total_loss=0.30579: 100%|█████████████████████| 100/100 [00:35<00:00,  2.80it/s]\n",
      "INFO:root:TRAINING EPOCH 32\n",
      "total_loss=0.05754:  20%|████▍                 | 20/100 [00:06<00:28,  2.78it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "total_loss=0.10808:  21%|████▌                 | 21/100 [00:08<00:53,  1.47it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "total_loss=0.11940: 100%|█████████████████████| 100/100 [00:31<00:00,  3.16it/s]\n",
      "INFO:root:Evaluating epoch 32\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:02,  4.12it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:03<00:00,  3.13it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 33\n",
      "total_loss=0.04085: 100%|█████████████████████| 100/100 [00:37<00:00,  2.68it/s]\n",
      "INFO:root:TRAINING EPOCH 34\n",
      "total_loss=0.04037: 100%|█████████████████████| 100/100 [00:38<00:00,  2.58it/s]\n",
      "INFO:root:Evaluating epoch 34\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:02,  4.26it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:04<00:00,  2.52it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 35\n",
      "total_loss=0.16649: 100%|█████████████████████| 100/100 [00:37<00:00,  2.63it/s]\n",
      "INFO:root:TRAINING EPOCH 36\n",
      "total_loss=0.03201: 100%|█████████████████████| 100/100 [00:33<00:00,  2.98it/s]\n",
      "INFO:root:Evaluating epoch 36\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:02,  3.95it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:03<00:00,  3.48it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:New best accuracy! 0.8916666666666667\n",
      "INFO:root:TRAINING EPOCH 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss=0.05969: 100%|█████████████████████| 100/100 [00:42<00:00,  2.37it/s]\n",
      "INFO:root:TRAINING EPOCH 38\n",
      "total_loss=0.22380: 100%|█████████████████████| 100/100 [00:29<00:00,  3.34it/s]\n",
      "INFO:root:Evaluating epoch 38\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:02,  4.44it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:03<00:00,  3.02it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 39\n",
      "total_loss=0.07910: 100%|█████████████████████| 100/100 [00:39<00:00,  2.54it/s]\n",
      "INFO:root:TRAINING EPOCH 40\n",
      "total_loss=0.13962: 100%|█████████████████████| 100/100 [00:38<00:00,  2.58it/s]\n",
      "INFO:root:Evaluating epoch 40\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:02,  4.43it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:04<00:00,  2.95it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 41\n",
      "total_loss=0.08392: 100%|█████████████████████| 100/100 [00:45<00:00,  2.18it/s]\n",
      "INFO:root:TRAINING EPOCH 42\n",
      "total_loss=0.02567: 100%|█████████████████████| 100/100 [00:51<00:00,  1.93it/s]\n",
      "INFO:root:Evaluating epoch 42\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 17%|███████▎                                    | 2/12 [00:00<00:03,  3.05it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:04<00:00,  2.51it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 43\n",
      "total_loss=0.03027: 100%|█████████████████████| 100/100 [00:37<00:00,  2.67it/s]\n",
      "INFO:root:TRAINING EPOCH 44\n",
      "total_loss=0.01895: 100%|█████████████████████| 100/100 [00:28<00:00,  3.51it/s]\n",
      "INFO:root:Evaluating epoch 44\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:02,  4.35it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:03<00:00,  3.05it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 45\n",
      "total_loss=0.13221: 100%|█████████████████████| 100/100 [00:32<00:00,  3.07it/s]\n",
      "INFO:root:TRAINING EPOCH 46\n",
      "total_loss=0.09949: 100%|█████████████████████| 100/100 [00:35<00:00,  2.81it/s]\n",
      "INFO:root:Evaluating epoch 46\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  8%|███▋                                        | 1/12 [00:00<00:06,  1.67it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:08<00:00,  1.39it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 47\n",
      "total_loss=0.01957: 100%|█████████████████████| 100/100 [00:38<00:00,  2.57it/s]\n",
      "INFO:root:TRAINING EPOCH 48\n",
      "total_loss=0.15287: 100%|█████████████████████| 100/100 [00:37<00:00,  2.64it/s]\n",
      "INFO:root:Evaluating epoch 48\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 25%|███████████                                 | 3/12 [00:00<00:01,  4.51it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:04<00:00,  2.45it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:TRAINING EPOCH 49\n",
      "total_loss=0.02287: 100%|█████████████████████| 100/100 [00:35<00:00,  2.80it/s]\n",
      "INFO:root:TRAINING EPOCH 50\n",
      "total_loss=0.09338: 100%|█████████████████████| 100/100 [00:27<00:00,  3.58it/s]\n",
      "INFO:root:Evaluating epoch 50\n",
      "INFO:root:Getting embeddings for the val split\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 17%|███████▎                                    | 2/12 [00:00<00:03,  3.24it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 12/12 [00:03<00:00,  3.16it/s]\n",
      "INFO:root:Computing accuracy for the val split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:Deleted self.models\n",
      "INFO:root:Deleted self.sampler\n",
      "INFO:root:Deleted self.loss_funcs\n",
      "INFO:root:Deleted self.mining_funcs\n",
      "INFO:root:Deleted self.optimizers\n",
      "INFO:root:Deleted self.lr_schedulers\n",
      "INFO:root:Deleted self.gradient_clippers\n",
      "INFO:root:Deleted self.record_keeper\n",
      "INFO:root:Deleted self.hooks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Deleted self.trainer\n",
      "INFO:root:Deleted self.tester\n"
     ]
    }
   ],
   "source": [
    "!rm -r experiments/targetlist-classdisjoint\n",
    "\n",
    "!python run.py --experiment_name \"targetlist-classdisjoint\" \\\n",
    "--dataset~OVERRIDE~ {LogoDatasetPlain: {root: /home/l/liny/ruofan/lightly/datasets/targetlist-merge/}} \\\n",
    "--hook_container~APPLY~2 {primary_metric: precision_at_1} \\\n",
    "--patience 20 \\\n",
    "--num_epochs_train 50 \\\n",
    "--loss_funcs~OVERRIDE~ {metric_loss~OVERRIDE~: {SoftTripleLoss: {num_classes: 277,  embedding_size: 128, centers_per_class: 10}}} \\\n",
    "--tester~APPLY~2 {accuracy_calculator: {AccuracyCalculator: {include: [precision_at_1], k: 1}}} \\\n",
    "--split_manager~APPLY~2 {data_and_label_getter_keys: null} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Importing packages in single_experiment_runner\n",
      "INFO:root:Importing packages in base_runner\n",
      "INFO:root:Done importing packages in base_runner\n",
      "INFO:root:Done importing packages in single_experiment_runner\n",
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "INFO:faiss.loader:Loading faiss.\n",
      "INFO:faiss.loader:Successfully loaded faiss.\n",
      "INFO:root:NUMPY_RANDOM = RandomState(MT19937)\n",
      "None\n",
      "INFO:root:train transform: Compose(\n",
      "    ConvertToBGR()\n",
      "    Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
      "    RandomResizedCrop(size=(227, 227), scale=(0.16, 1), ratio=(0.75, 1.33), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ToTensor()\n",
      "    Multiplier(multiple=255)\n",
      "    Normalize(mean=[104, 117, 128], std=[1, 1, 1])\n",
      ")\n",
      "INFO:root:eval transform: Compose(\n",
      "    ConvertToBGR()\n",
      "    Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
      "    CenterCrop(size=(227, 227))\n",
      "    ToTensor()\n",
      "    Multiplier(multiple=255)\n",
      "    Normalize(mean=[104, 117, 128], std=[1, 1, 1])\n",
      ")\n",
      "INFO:root:Asserted: the ['test'] set indices are equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['train'] set indices are not_equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['val'] set indices are not_equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['train', 'val', 'test'] set indices are disjoint within split_scheme_names\n",
      "INFO:root:Asserted: the ['test'] set indices are equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['train'] set indices are not_equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['val'] set indices are not_equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['train', 'val', 'test'] set indices are disjoint within split_scheme_names\n",
      "INFO:root:Asserted: the ['train', 'val', 'test'] set indices are equal across transform_types\n",
      "INFO:root:Asserted: the ['val'] set indices are disjoint across split_scheme_names\n",
      "INFO:root:Asserted: the ['val'] set indices are disjoint across split_scheme_names\n",
      "INFO:root:Asserted: the ['train', 'val', 'test'] set class labels are disjoint within split_scheme_names\n",
      "INFO:root:Asserted: the ['train', 'val', 'test'] set class labels are disjoint within split_scheme_names\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:trunk_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:embedder_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_0 / train / length 1223 / using train transform\n",
      "INFO:root:Creating end_of_epoch_hook\n",
      "INFO:root:Getting split: Test50_50_Partitions4_0 / test / length 1279 / using eval transform\n",
      "INFO:root:Launching evaluation for model untrained_trunk\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:Getting split: Test50_50_Partitions4_0 / test / length 1279 / using eval transform\n",
      "INFO:root:Evaluating epoch -1\n",
      "INFO:root:Getting embeddings for the test split\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 32%|█████████████▉                             | 13/40 [00:11<00:23,  1.13it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 40/40 [00:15<00:00,  2.52it/s]\n",
      "INFO:root:Computing accuracy for the test split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 1024\n",
      "INFO:root:Launching evaluation for model untrained_trunk_and_embedder\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_0 / test / length 1279 / using eval transform\n",
      "INFO:root:Evaluating epoch 0\n",
      "INFO:root:Getting embeddings for the test split\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 30%|████████████▉                              | 12/40 [00:03<00:05,  4.71it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 40/40 [00:09<00:00,  4.30it/s]\n",
      "INFO:root:Computing accuracy for the test split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:Launching evaluation for model best\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_0/saved_models/trunk_best46.pth\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_0/saved_models/embedder_best46.pth\n",
      "INFO:root:Getting split: Test50_50_Partitions4_0 / test / length 1279 / using eval transform\n",
      "INFO:root:Evaluating epoch 46\n",
      "INFO:root:Getting embeddings for the test split\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 32%|█████████████▉                             | 13/40 [00:05<00:08,  3.20it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 40/40 [00:11<00:00,  3.63it/s]\n",
      "INFO:root:Computing accuracy for the test split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:Deleted self.models\n",
      "INFO:root:Deleted self.sampler\n",
      "INFO:root:Deleted self.loss_funcs\n",
      "INFO:root:Deleted self.mining_funcs\n",
      "INFO:root:Deleted self.optimizers\n",
      "INFO:root:Deleted self.lr_schedulers\n",
      "INFO:root:Deleted self.gradient_clippers\n",
      "INFO:root:Deleted self.record_keeper\n",
      "INFO:root:Deleted self.hooks\n",
      "INFO:root:Deleted self.trainer\n",
      "INFO:root:Deleted self.tester\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:trunk_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:embedder_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_1 / train / length 1224 / using train transform\n",
      "INFO:root:Creating end_of_epoch_hook\n",
      "INFO:root:Getting split: Test50_50_Partitions4_1 / test / length 1279 / using eval transform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Launching evaluation for model untrained_trunk\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:Getting split: Test50_50_Partitions4_1 / test / length 1279 / using eval transform\n",
      "INFO:root:Evaluating epoch -1\n",
      "INFO:root:Getting embeddings for the test split\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 30%|████████████▉                              | 12/40 [00:03<00:05,  4.70it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 40/40 [00:09<00:00,  4.40it/s]\n",
      "INFO:root:Computing accuracy for the test split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 1024\n",
      "INFO:root:Launching evaluation for model untrained_trunk_and_embedder\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_1 / test / length 1279 / using eval transform\n",
      "INFO:root:Evaluating epoch 0\n",
      "INFO:root:Getting embeddings for the test split\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 32%|█████████████▉                             | 13/40 [00:05<00:05,  4.53it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 40/40 [00:10<00:00,  3.92it/s]\n",
      "INFO:root:Computing accuracy for the test split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:Launching evaluation for model best\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_1/saved_models/trunk_best28.pth\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_1/saved_models/embedder_best28.pth\n",
      "INFO:root:Getting split: Test50_50_Partitions4_1 / test / length 1279 / using eval transform\n",
      "INFO:root:Evaluating epoch 28\n",
      "INFO:root:Getting embeddings for the test split\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 32%|█████████████▉                             | 13/40 [00:03<00:05,  5.30it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 40/40 [00:07<00:00,  5.59it/s]\n",
      "INFO:root:Computing accuracy for the test split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:Deleted self.models\n",
      "INFO:root:Deleted self.sampler\n",
      "INFO:root:Deleted self.loss_funcs\n",
      "INFO:root:Deleted self.mining_funcs\n",
      "INFO:root:Deleted self.optimizers\n",
      "INFO:root:Deleted self.lr_schedulers\n",
      "INFO:root:Deleted self.gradient_clippers\n",
      "INFO:root:Deleted self.record_keeper\n",
      "INFO:root:Deleted self.hooks\n",
      "INFO:root:Deleted self.trainer\n",
      "INFO:root:Deleted self.tester\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:trunk_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:embedder_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_2 / train / length 1281 / using train transform\n",
      "INFO:root:Creating end_of_epoch_hook\n",
      "INFO:root:Getting split: Test50_50_Partitions4_2 / test / length 1279 / using eval transform\n",
      "INFO:root:Launching evaluation for model untrained_trunk\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:Getting split: Test50_50_Partitions4_2 / test / length 1279 / using eval transform\n",
      "INFO:root:Evaluating epoch -1\n",
      "INFO:root:Getting embeddings for the test split\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 32%|█████████████▉                             | 13/40 [00:05<00:13,  1.97it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 40/40 [00:08<00:00,  4.47it/s]\n",
      "INFO:root:Computing accuracy for the test split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 1024\n",
      "INFO:root:Launching evaluation for model untrained_trunk_and_embedder\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_2 / test / length 1279 / using eval transform\n",
      "INFO:root:Evaluating epoch 0\n",
      "INFO:root:Getting embeddings for the test split\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 32%|█████████████▉                             | 13/40 [00:02<00:03,  6.87it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 40/40 [00:06<00:00,  5.75it/s]\n",
      "INFO:root:Computing accuracy for the test split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:Launching evaluation for model best\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_2/saved_models/trunk_best40.pth\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_2/saved_models/embedder_best40.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Getting split: Test50_50_Partitions4_2 / test / length 1279 / using eval transform\n",
      "INFO:root:Evaluating epoch 40\n",
      "INFO:root:Getting embeddings for the test split\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 35%|███████████████                            | 14/40 [00:04<00:17,  1.50it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 40/40 [00:08<00:00,  4.45it/s]\n",
      "INFO:root:Computing accuracy for the test split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:Deleted self.models\n",
      "INFO:root:Deleted self.sampler\n",
      "INFO:root:Deleted self.loss_funcs\n",
      "INFO:root:Deleted self.mining_funcs\n",
      "INFO:root:Deleted self.optimizers\n",
      "INFO:root:Deleted self.lr_schedulers\n",
      "INFO:root:Deleted self.gradient_clippers\n",
      "INFO:root:Deleted self.record_keeper\n",
      "INFO:root:Deleted self.hooks\n",
      "INFO:root:Deleted self.trainer\n",
      "INFO:root:Deleted self.tester\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:trunk_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:embedder_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_3 / train / length 1324 / using train transform\n",
      "INFO:root:Creating end_of_epoch_hook\n",
      "INFO:root:Getting split: Test50_50_Partitions4_3 / test / length 1279 / using eval transform\n",
      "INFO:root:Launching evaluation for model untrained_trunk\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:Getting split: Test50_50_Partitions4_3 / test / length 1279 / using eval transform\n",
      "INFO:root:Evaluating epoch -1\n",
      "INFO:root:Getting embeddings for the test split\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 32%|█████████████▉                             | 13/40 [00:02<00:04,  5.66it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 40/40 [00:08<00:00,  4.89it/s]\n",
      "INFO:root:Computing accuracy for the test split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 1024\n",
      "INFO:root:Launching evaluation for model untrained_trunk_and_embedder\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_3 / test / length 1279 / using eval transform\n",
      "INFO:root:Evaluating epoch 0\n",
      "INFO:root:Getting embeddings for the test split\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 32%|█████████████▉                             | 13/40 [00:04<00:07,  3.51it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 40/40 [00:08<00:00,  4.61it/s]\n",
      "INFO:root:Computing accuracy for the test split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:Launching evaluation for model best\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_3/saved_models/trunk_best36.pth\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_3/saved_models/embedder_best36.pth\n",
      "INFO:root:Getting split: Test50_50_Partitions4_3 / test / length 1279 / using eval transform\n",
      "INFO:root:Evaluating epoch 36\n",
      "INFO:root:Getting embeddings for the test split\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      " 32%|█████████████▉                             | 13/40 [00:02<00:04,  6.10it/s]/home/l/liny/anaconda3/envs/metric-learning/lib/python3.7/site-packages/PIL/Image.py:963: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|███████████████████████████████████████████| 40/40 [00:08<00:00,  4.69it/s]\n",
      "INFO:root:Computing accuracy for the test split\n",
      "INFO:root:running k-nn with k=1\n",
      "INFO:root:embedding dimensionality is 128\n",
      "INFO:root:Deleted self.models\n",
      "INFO:root:Deleted self.sampler\n",
      "INFO:root:Deleted self.loss_funcs\n",
      "INFO:root:Deleted self.mining_funcs\n",
      "INFO:root:Deleted self.optimizers\n",
      "INFO:root:Deleted self.lr_schedulers\n",
      "INFO:root:Deleted self.gradient_clippers\n",
      "INFO:root:Deleted self.record_keeper\n",
      "INFO:root:Deleted self.hooks\n",
      "INFO:root:Deleted self.trainer\n",
      "INFO:root:Deleted self.tester\n"
     ]
    }
   ],
   "source": [
    "!python run.py \\\n",
    "--experiment_name \"targetlist-classdisjoint\" \\\n",
    "--evaluate --splits_to_eval [test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Importing packages in single_experiment_runner\n",
      "INFO:root:Importing packages in base_runner\n",
      "INFO:root:Done importing packages in base_runner\n",
      "INFO:root:Done importing packages in single_experiment_runner\n",
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "INFO:faiss.loader:Loading faiss.\n",
      "INFO:faiss.loader:Successfully loaded faiss.\n",
      "INFO:root:NUMPY_RANDOM = RandomState(MT19937)\n",
      "None\n",
      "INFO:root:train transform: Compose(\n",
      "    ConvertToBGR()\n",
      "    Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
      "    RandomResizedCrop(size=(227, 227), scale=(0.16, 1), ratio=(0.75, 1.33), interpolation=PIL.Image.BILINEAR)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ToTensor()\n",
      "    Multiplier(multiple=255)\n",
      "    Normalize(mean=[104, 117, 128], std=[1, 1, 1])\n",
      ")\n",
      "INFO:root:eval transform: Compose(\n",
      "    ConvertToBGR()\n",
      "    Resize(size=256, interpolation=PIL.Image.BILINEAR)\n",
      "    CenterCrop(size=(227, 227))\n",
      "    ToTensor()\n",
      "    Multiplier(multiple=255)\n",
      "    Normalize(mean=[104, 117, 128], std=[1, 1, 1])\n",
      ")\n",
      "INFO:root:Asserted: the ['test'] set indices are equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['train'] set indices are not_equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['val'] set indices are not_equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['train', 'val', 'test'] set indices are disjoint within split_scheme_names\n",
      "INFO:root:Asserted: the ['test'] set indices are equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['train'] set indices are not_equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['val'] set indices are not_equal across split_scheme_names\n",
      "INFO:root:Asserted: the ['train', 'val', 'test'] set indices are disjoint within split_scheme_names\n",
      "INFO:root:Asserted: the ['train', 'val', 'test'] set indices are equal across transform_types\n",
      "INFO:root:Asserted: the ['val'] set indices are disjoint across split_scheme_names\n",
      "INFO:root:Asserted: the ['val'] set indices are disjoint across split_scheme_names\n",
      "INFO:root:Asserted: the ['train', 'val', 'test'] set class labels are disjoint within split_scheme_names\n",
      "INFO:root:Asserted: the ['train', 'val', 'test'] set class labels are disjoint within split_scheme_names\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:trunk_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:embedder_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_0 / train / length 1223 / using train transform\n",
      "INFO:root:Creating end_of_epoch_hook\n",
      "INFO:root:Getting split: Test50_50_Partitions4_0 / val / length 461 / using eval transform\n",
      "INFO:root:Launching evaluation for model untrained_trunk\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:Getting split: Test50_50_Partitions4_0 / val / length 461 / using eval transform\n",
      "INFO:root:Already evaluated\n",
      "INFO:root:Launching evaluation for model untrained_trunk_and_embedder\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_0 / val / length 461 / using eval transform\n",
      "INFO:root:Already evaluated\n",
      "INFO:root:Launching evaluation for model best\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_0/saved_models/trunk_best46.pth\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_0/saved_models/embedder_best46.pth\n",
      "INFO:root:Getting split: Test50_50_Partitions4_0 / val / length 461 / using eval transform\n",
      "INFO:root:Already evaluated\n",
      "INFO:root:Deleted self.models\n",
      "INFO:root:Deleted self.sampler\n",
      "INFO:root:Deleted self.loss_funcs\n",
      "INFO:root:Deleted self.mining_funcs\n",
      "INFO:root:Deleted self.optimizers\n",
      "INFO:root:Deleted self.lr_schedulers\n",
      "INFO:root:Deleted self.gradient_clippers\n",
      "INFO:root:Deleted self.record_keeper\n",
      "INFO:root:Deleted self.hooks\n",
      "INFO:root:Deleted self.trainer\n",
      "INFO:root:Deleted self.tester\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:trunk_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:embedder_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_1 / train / length 1224 / using train transform\n",
      "INFO:root:Creating end_of_epoch_hook\n",
      "INFO:root:Getting split: Test50_50_Partitions4_1 / val / length 460 / using eval transform\n",
      "INFO:root:Launching evaluation for model untrained_trunk\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:Getting split: Test50_50_Partitions4_1 / val / length 460 / using eval transform\n",
      "INFO:root:Already evaluated\n",
      "INFO:root:Launching evaluation for model untrained_trunk_and_embedder\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_1 / val / length 460 / using eval transform\n",
      "INFO:root:Already evaluated\n",
      "INFO:root:Launching evaluation for model best\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_1/saved_models/trunk_best28.pth\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_1/saved_models/embedder_best28.pth\n",
      "INFO:root:Getting split: Test50_50_Partitions4_1 / val / length 460 / using eval transform\n",
      "INFO:root:Already evaluated\n",
      "INFO:root:Deleted self.models\n",
      "INFO:root:Deleted self.sampler\n",
      "INFO:root:Deleted self.loss_funcs\n",
      "INFO:root:Deleted self.mining_funcs\n",
      "INFO:root:Deleted self.optimizers\n",
      "INFO:root:Deleted self.lr_schedulers\n",
      "INFO:root:Deleted self.gradient_clippers\n",
      "INFO:root:Deleted self.record_keeper\n",
      "INFO:root:Deleted self.hooks\n",
      "INFO:root:Deleted self.trainer\n",
      "INFO:root:Deleted self.tester\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:trunk_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:embedder_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_2 / train / length 1281 / using train transform\n",
      "INFO:root:Creating end_of_epoch_hook\n",
      "INFO:root:Getting split: Test50_50_Partitions4_2 / val / length 403 / using eval transform\n",
      "INFO:root:Launching evaluation for model untrained_trunk\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:Getting split: Test50_50_Partitions4_2 / val / length 403 / using eval transform\n",
      "INFO:root:Already evaluated\n",
      "INFO:root:Launching evaluation for model untrained_trunk_and_embedder\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_2 / val / length 403 / using eval transform\n",
      "INFO:root:Already evaluated\n",
      "INFO:root:Launching evaluation for model best\n",
      "INFO:root:Initializing/loading models for evaluation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_2/saved_models/trunk_best40.pth\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_2/saved_models/embedder_best40.pth\n",
      "INFO:root:Getting split: Test50_50_Partitions4_2 / val / length 403 / using eval transform\n",
      "INFO:root:Already evaluated\n",
      "INFO:root:Deleted self.models\n",
      "INFO:root:Deleted self.sampler\n",
      "INFO:root:Deleted self.loss_funcs\n",
      "INFO:root:Deleted self.mining_funcs\n",
      "INFO:root:Deleted self.optimizers\n",
      "INFO:root:Deleted self.lr_schedulers\n",
      "INFO:root:Deleted self.gradient_clippers\n",
      "INFO:root:Deleted self.record_keeper\n",
      "INFO:root:Deleted self.hooks\n",
      "INFO:root:Deleted self.trainer\n",
      "INFO:root:Deleted self.tester\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:trunk_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:embedder_optimizer\n",
      "RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 1e-08\n",
      "    lr: 1e-06\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_3 / train / length 1324 / using train transform\n",
      "INFO:root:Creating end_of_epoch_hook\n",
      "INFO:root:Getting split: Test50_50_Partitions4_3 / val / length 360 / using eval transform\n",
      "INFO:root:Launching evaluation for model untrained_trunk\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:Getting split: Test50_50_Partitions4_3 / val / length 360 / using eval transform\n",
      "INFO:root:Already evaluated\n",
      "INFO:root:Launching evaluation for model untrained_trunk_and_embedder\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:Getting split: Test50_50_Partitions4_3 / val / length 360 / using eval transform\n",
      "INFO:root:Already evaluated\n",
      "INFO:root:Launching evaluation for model best\n",
      "INFO:root:Initializing/loading models for evaluation\n",
      "INFO:root:EMBEDDER MODEL MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
      "  )\n",
      "  (last_linear): Linear(in_features=1024, out_features=128, bias=True)\n",
      ")\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_3/saved_models/trunk_best36.pth\n",
      "INFO:root:LOAD experiments/targetlist-classdisjoint/Test50_50_Partitions4_3/saved_models/embedder_best36.pth\n",
      "INFO:root:Getting split: Test50_50_Partitions4_3 / val / length 360 / using eval transform\n",
      "INFO:root:Already evaluated\n",
      "INFO:root:Deleted self.models\n",
      "INFO:root:Deleted self.sampler\n",
      "INFO:root:Deleted self.loss_funcs\n",
      "INFO:root:Deleted self.mining_funcs\n",
      "INFO:root:Deleted self.optimizers\n",
      "INFO:root:Deleted self.lr_schedulers\n",
      "INFO:root:Deleted self.gradient_clippers\n",
      "INFO:root:Deleted self.record_keeper\n",
      "INFO:root:Deleted self.hooks\n",
      "INFO:root:Deleted self.trainer\n",
      "INFO:root:Deleted self.tester\n"
     ]
    }
   ],
   "source": [
    "!python run.py \\\n",
    "--experiment_name \"targetlist-classdisjoint\" \\\n",
    "--evaluate --splits_to_eval [val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV-Split 1\n",
      "Best validation accuracy: 0.8004338394793926\n",
      "Best testing accuracy: 0.7670054730258014\n",
      "CV-Split 2\n",
      "Best validation accuracy: 0.8782608695652174\n",
      "Best testing accuracy: 0.799061767005473\n",
      "CV-Split 3\n",
      "Best validation accuracy: 0.890818858560794\n",
      "Best testing accuracy: 0.8162627052384676\n",
      "CV-Split 4\n",
      "Best validation accuracy: 0.8916666666666667\n",
      "Best testing accuracy: 0.8170445660672401\n",
      "0.8652950585680177\n",
      "0.7998436278342456\n"
     ]
    }
   ],
   "source": [
    "# get accuracy\n",
    "exp_name = 'targetlist-classdisjoint'\n",
    "average_val_acc = []\n",
    "average_test_acc = []\n",
    "\n",
    "for i in range(4):\n",
    "    basedir = os.path.join('experiments/{}/Test50_50_Partitions4_{}/'.format(exp_name, i), 'saved_csvs')\n",
    "    val_csvpath = os.path.join(basedir, 'accuracies_normalized_compared_to_self_GlobalEmbeddingSpaceTester_level_0_VAL.csv')\n",
    "    test_csvpath = os.path.join(basedir, 'accuracies_normalized_compared_to_self_GlobalEmbeddingSpaceTester_level_0_TEST.csv')\n",
    "    val_df = pd.read_csv(val_csvpath)\n",
    "    test_df = pd.read_csv(test_csvpath)   \n",
    "    \n",
    "    print('CV-Split {}'.format(i+1))\n",
    "    print('Best validation accuracy: {}'.format(val_df.iloc[-1, :]['best_accuracy']))\n",
    "    print('Best testing accuracy: {}'.format(test_df.iloc[-1, :]['best_accuracy']))    \n",
    "    average_val_acc.append(val_df.iloc[-1, :]['best_accuracy'])\n",
    "    average_test_acc.append(test_df.iloc[-1, :]['best_accuracy'])\n",
    "\n",
    "print(np.mean(average_val_acc))\n",
    "print(np.mean(average_test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
